{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Setup working directory and path to study area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/WUR/duku002/Scripts/drought_floods/vscode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir='/lustre/backup/WUR/ESG/duku002/Drought-Flood-Cascade/rhine'\n",
    "study_area='/home/WUR/duku002/Scripts/NBAT/hydro/common_data/rhine.shp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 .Download and preprocess input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# download and preprocess MODIS vegetation continuous fields from Google Earth Engine Data catalog\n",
    "\n",
    "from bakaano.tree_cover import TreeCover\n",
    "vf = TreeCover(\n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area, \n",
    "    start_date='2001-01-01', \n",
    "    end_date='2020-12-31'\n",
    ")\n",
    "vf.get_tree_cover_data()\n",
    "vf.plot_tree_cover(variable='tree_cover') # options for plot are 'tree_cover' and 'herb_cover'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download and preprocess MODIS NDVI data from Google Earth Engine Data catalog\n",
    "\n",
    "from bakaano.ndvi import NDVI\n",
    "nd = NDVI(\n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area, \n",
    "    start_date='2001-01-01', \n",
    "    end_date='2010-12-31'\n",
    ")\n",
    "nd.get_ndvi_data()\n",
    "nd.plot_ndvi(interval_num=10)  # because NDVI is in 16-day interval the 'interval_num' represents a 16-day period. \n",
    "                               #Hence 0 is the first 16 day period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get elevation data\n",
    "\n",
    "from bakaano.dem import DEM\n",
    "dd = DEM(\n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area, \n",
    "    local_data=False, \n",
    "    local_data_path=None\n",
    ")\n",
    "dd.get_dem_data()\n",
    "dd.plot_dem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get soil data\n",
    "\n",
    "from bakaano.soil import Soil\n",
    "sgd = Soil(\n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area\n",
    ")\n",
    "sgd.get_soil_data()\n",
    "sgd.plot_soil(variable='wilting_point')  #options are 'wilting_point', 'saturation_point' and 'available_water_content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get alpha earth satellite embedding dataset\n",
    "\n",
    "from bakaano.alpha_earth import AlphaEarth\n",
    "dd = AlphaEarth(\n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area,\n",
    "    start_date='2013-01-01', \n",
    "    end_date = '2024-01-01'\n",
    ")\n",
    "dd.get_alpha_earth()\n",
    "dd.plot_alpha_earth('A35') #Band options are A00 to A63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get meteo\n",
    "\n",
    "from bakaano.meteo import Meteo\n",
    "cd = Meteo(\n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area, \n",
    "    start_date='2001-01-01', \n",
    "    end_date='2010-12-31',\n",
    "    local_data=False, \n",
    "    data_source='ERA5'\n",
    ")\n",
    "cd.plot_meteo(variable='tasmin', date='2006-12-01') # variable options are 'tmean', 'precip', 'tasmax', 'tasmin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   3. Computing runoff and routing to river network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bakaano.veget import VegET\n",
    "vg = VegET(\n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area,\n",
    "    start_date='2001-01-01', \n",
    "    end_date='2010-12-31',\n",
    "    climate_data_source='ERA5',\n",
    "    routing_method='mfd'\n",
    ")\n",
    "vg.compute_veget_runoff_route_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize routed runoff data\n",
    "\n",
    "from bakaano.plot_runoff import RoutedRunoff\n",
    "rr = RoutedRunoff(\n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area\n",
    ")\n",
    "rr.map_routed_runoff(date='2020-01-03', vmax=7) #output values have been log transformed for better visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.interactive_plot_routed_runoff_timeseries(start_date='2000-01-01', end_date='2000-12-31', \n",
    "                                             grdc_netcdf='/lustre/backup/WUR/ESG/duku002/NBAT/hydro/input_data/GRDC-Daily-EU.nc'\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   4. Explore input data, river networks and hydrological stations interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bakaano.runner import BakaanoHydro\n",
    "bk = BakaanoHydro(\n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area,\n",
    "    climate_data_source='ERA5'\n",
    ")\n",
    "bk.explore_data_interactively('1981-01-01', '2016-12-31', '/lustre/backup/WUR/ESG/duku002/NBAT/hydro/input_data/GRDC-Daily-africa-south-america.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   5. Training, Evaluating and Applying Bakaano-Hydro model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZE INSTANCE OF BAKAANO-HYDRO MODEL\n",
    "\n",
    "from bakaano.runner import BakaanoHydro\n",
    "bk = BakaanoHydro(  \n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area,\n",
    "    climate_data_source='ERA5'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING BAKAANO-HYDRO MODEL\n",
    "\n",
    "# The model is trained using the GRDC streamflow data.\n",
    "# Note: The training process is computationally expensive and may take a long time to complete.\n",
    "# trained model is always in the models folder in the working_dir and with a .keras extension\n",
    "\n",
    "\n",
    "bk.train_streamflow_model(\n",
    "    train_start='1981-01-01', \n",
    "    train_end='2020-12-31', \n",
    "    grdc_netcdf='/lustre/backup/WUR/ESG/duku002/NBAT/hydro/input_data/GRDC-Daily-africa-south-america.nc', \n",
    "    batch_size=32, \n",
    "    num_epochs=300,\n",
    "    learning_rate=0.001  #for fewer stations reduce learning rate to 0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   5c. Optional: Evaluate/Simulate with observed CSV files\n",
    "Use the same lookup table and station CSV directory as training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate interactively using CSV observations (enter station id when prompted)\n",
    "model_path = f'{working_dir}/models/bakaano_model.keras'\n",
    "\n",
    "bk.evaluate_streamflow_model_interactively(\n",
    "    model_path=model_path,\n",
    "    val_start='2001-01-01',\n",
    "    val_end='2010-12-31',\n",
    "    grdc_netcdf=None,\n",
    "    csv_dir='/path/to/observed_csvs',\n",
    "    lookup_csv='/path/to/station_lookup.csv'\n",
    ")\n",
    "\n",
    "# Batch prediction for stations listed in lookup CSV\n",
    "bk.simulate_grdc_stations(\n",
    "    model_path=model_path,\n",
    "    sim_start='1981-01-01',\n",
    "    sim_end='2020-12-31',\n",
    "    grdc_netcdf=None,\n",
    "    csv_dir='/path/to/observed_csvs',\n",
    "    lookup_csv='/path/to/station_lookup.csv'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATING THE TRAINED MODEL INTERACTIVELY\n",
    "\n",
    "# The model is evaluated using the GRDC streamflow data.\n",
    "\n",
    "\n",
    "# trained model is always in the models folder in the working_dir and with a .keras extension\n",
    "# the model names is always in the format: bakaano_model_<loss_fn>_<num_input_branch>_branches.keras\n",
    "model_path = f'{working_dir}/models/bakaano_model.keras' \n",
    "\n",
    "bk.evaluate_streamflow_model_interactively(\n",
    "    model_path=model_path, \n",
    "    val_start='2001-01-01', \n",
    "    val_end='2010-12-31', \n",
    "    grdc_netcdf='/lustre/backup/WUR/ESG/duku002/NBAT/hydro/input_data/GRDC-Daily-africa-south-america.nc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch prediction for GRDC stations\n",
    "\n",
    "model_path = f'{working_dir}/models/bakaano_model.keras'\n",
    "\n",
    "bk.simulate_grdc_stations(\n",
    "    model_path=model_path, \n",
    "    sim_start='1981-01-01', \n",
    "    sim_end='2020-12-31', \n",
    "    grdc_netcdf='/lustre/backup/WUR/ESG/duku002/NBAT/hydro/input_data/GRDC-Daily-africa-south-america.nc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTING STREAMFLOW USING THE TRAINED MODEL AND STORING AS CSV FILES \n",
    "# The model is used to predict streamflow in any location in the study area. \n",
    "\n",
    "model_path = f'{working_dir}/models/bakaano_model.keras'\n",
    "\n",
    "bk.simulate_streamflow(\n",
    "    model_path=model_path, \n",
    "    sim_start='1981-01-01', \n",
    "    sim_end='1990-12-31', \n",
    "    latlist=[13.8, 13.9],\n",
    "    lonlist=[3.0, 4.0]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bakaano",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
