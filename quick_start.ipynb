{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   1. Getting and preprocessing input data\n",
    "\n",
    "If you have previously executed this step and downloaded all input data you can skip this step and proceed directly to step 2. However, if you are not sure, run step 1 and the model will either confirm that a specific data has aready been downloaded and subsequently viualize it or it will proceeed to download the data if it is not available or prior download was incomplete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/WUR/duku002/Scripts/drought_floods/vscode\n"
     ]
    }
   ],
   "source": [
    "%cd /home/WUR/duku002/Scripts/drought_floods/vscode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir='/lustre/backup/WUR/ESG/duku002/Drought-Flood-Cascade/niger'\n",
    "study_area='/home/WUR/duku002/Scripts/NBAT/hydro/common_data/niger.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# download and preprocess MODIS vegetation continuous fields from Google Earth Engine Data catalog\n",
    "\n",
    "from bakaano.tree_cover import TreeCover\n",
    "vf = TreeCover(\n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area, \n",
    "    start_date='2001-01-01', \n",
    "    end_date='2020-12-31'\n",
    ")\n",
    "vf.get_tree_cover_data()\n",
    "vf.plot_tree_cover(variable='tree_cover') # options for plot are 'tree_cover' and 'herb_cover'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download and preprocess MODIS NDVI data from Google Earth Engine Data catalog\n",
    "\n",
    "from bakaano.ndvi import NDVI\n",
    "nd = NDVI(\n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area, \n",
    "    start_date='2001-01-01', \n",
    "    end_date='2010-12-31'\n",
    ")\n",
    "nd.get_ndvi_data()\n",
    "nd.plot_ndvi(interval_num=10)  # because NDVI is in 16-day interval the 'interval_num' represents a 16-day period. \n",
    "                               #Hence 0 is the first 16 day period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get elevation data\n",
    "\n",
    "from bakaano.dem import DEM\n",
    "dd = DEM(\n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area, \n",
    "    local_data=False, \n",
    "    local_data_path=None\n",
    ")\n",
    "dd.get_dem_data()\n",
    "dd.plot_dem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get soil data\n",
    "\n",
    "from bakaano.soil import Soil\n",
    "sgd = Soil(\n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area\n",
    ")\n",
    "sgd.get_soil_data()\n",
    "sgd.plot_soil(variable='wilting_point')  #options are 'wilting_point', 'saturation_point' and 'available_water_content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get alpha earth satellite embedding dataset\n",
    "\n",
    "from bakaano.alpha_earth import AlphaEarth\n",
    "dd = AlphaEarth(\n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area,\n",
    "    start_date='2013-01-01', \n",
    "    end_date = '2024-01-01',\n",
    ")\n",
    "dd.get_alpha_earth()\n",
    "dd.plot_alpha_earth('A35') #Band options are A00 to A63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get meteo\n",
    "\n",
    "from bakaano.meteo import Meteo\n",
    "cd = Meteo(\n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area, \n",
    "    start_date='2001-01-01', \n",
    "    end_date='2010-12-31',\n",
    "    local_data=False, \n",
    "    data_source='ERA5'\n",
    ")\n",
    "cd.plot_meteo(variable='tasmin', date='2006-12-01') # variable options are 'tmean', 'precip', 'tasmax', 'tasmin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   2. Computing runoff and routing to river network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bakaano.veget import VegET\n",
    "vg = VegET(\n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area,\n",
    "    start_date='2001-01-01', \n",
    "    end_date='2010-12-31',\n",
    "    climate_data_source='ERA5',\n",
    "    routing_method='mfd'\n",
    ")\n",
    "vg.compute_veget_runoff_route_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize routed runoff data\n",
    "\n",
    "from bakaano.plot_runoff import RoutedRunoff\n",
    "rr = RoutedRunoff(\n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area\n",
    ")\n",
    "rr.map_routed_runoff(date='2020-09-03', vmax=6) #output values have been log transformed for better visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   3. Explore input data, river networks and hydrological stations interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bakaano.runner import BakaanoHydro\n",
    "bk = BakaanoHydro(\n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area,\n",
    "    climate_data_source='ERA5'\n",
    ")\n",
    "bk.explore_data_interactively('1981-01-01', '2016-12-31', '/lustre/backup/WUR/ESG/duku002/NBAT/hydro/input_data/GRDC-Daily-africa-south-america.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   4. Training, Evaluating and Applying Bakaano-Hydro model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 19:47:56.857331: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767293276.870993  130325 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767293276.875274  130325 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZE INSTANCE OF BAKAANO-HYDRO MODEL\n",
    "\n",
    "from bakaano.runner import BakaanoHydro\n",
    "bk = BakaanoHydro(  \n",
    "    working_dir=working_dir, \n",
    "    study_area=study_area,\n",
    "    climate_data_source='ERA5'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING BAKAANO-HYDRO MODEL\n",
    "\n",
    "# The model is trained using the GRDC streamflow data.\n",
    "# Note: The training process is computationally expensive and may take a long time to complete.\n",
    "# trained model is always in the models folder in the working_dir and with a .keras extension\n",
    "# the model names is always in the format: bakaano_model_<loss_fn>_<num_input_branch>_branches.keras\n",
    "\n",
    "bk.train_streamflow_model(\n",
    "    train_start='1991-01-01', \n",
    "    train_end='2020-12-31', \n",
    "    grdc_netcdf='/lustre/backup/WUR/ESG/duku002/NBAT/hydro/input_data/GRDC-Daily-africa-south-america.nc', \n",
    "    batch_size=1024, \n",
    "    num_epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATING THE TRAINED MODEL INTERACTIVELY\n",
    "\n",
    "# The model is evaluated using the GRDC streamflow data.\n",
    "\n",
    "\n",
    "# trained model is always in the models folder in the working_dir and with a .keras extension\n",
    "# the model names is always in the format: bakaano_model_<loss_fn>_<num_input_branch>_branches.keras\n",
    "model_path = f'{working_dir}/models/bakaano_model.keras' \n",
    "\n",
    "bk.evaluate_streamflow_model_interactively(\n",
    "    model_path=model_path, \n",
    "    val_start='1981-01-01', \n",
    "    val_end='1990-12-31', \n",
    "    grdc_netcdf='/lustre/backup/WUR/ESG/duku002/NBAT/hydro/input_data/GRDC-Daily-africa-south-america.nc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. Loading runoff data and other predictors\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 19:53:55.603835: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2. Batch prediction\n",
      "\u001b[1m2557/2557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step\n",
      " 3. Generating csv file for each coordinate\n",
      " COMPLETED! csv files available at /lustre/backup/WUR/ESG/duku002/Drought-Flood-Cascade/niger/predicted_streamflow_data\n"
     ]
    }
   ],
   "source": [
    "# PREDICTING STREAMFLOW USING THE TRAINED MODEL AND STORING AS CSV FILES \n",
    "# The model is used to predict streamflow in any location in the study area. \n",
    "\n",
    "model_path = f'{working_dir}/models/bakaano_model.keras'\n",
    "\n",
    "bk.simulate_streamflow(\n",
    "    model_path=model_path, \n",
    "    sim_start='1981-01-01', \n",
    "    sim_end='1988-12-31', \n",
    "    latlist=[13.8, 13.9],\n",
    "    lonlist=[3.0, 4.0]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bakaano-hydro",
   "language": "python",
   "name": "bakaano-hydro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
